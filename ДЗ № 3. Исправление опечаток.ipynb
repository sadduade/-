{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0786c9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from nltk import sent_tokenize\n",
    "punctuation += \"«»—…“”\"\n",
    "punct = set(punctuation)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "from difflib import get_close_matches\n",
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8dac3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textdistance in c:\\users\\пользователь\\appdata\\roaming\\python\\python311\\site-packages (4.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1b87ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e0b4688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62799b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b692335",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('correct_sents.txt', encoding='utf8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b92b04e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "915"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa60afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('wiki_data.txt', encoding='utf8').read()\n",
    "vocab = Counter(re.findall('\\w+', corpus.lower()))\n",
    "\n",
    "word2id = list(vocab.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "vec = CountVectorizer(analyzer='char', ngram_range=(1,1))\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7b8f647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mistaken(word, vocab):\n",
    "    return 0 if word in vocab else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9275e21d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'align_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(true)):\n\u001b[1;32m----> 5\u001b[0m     word_pairs \u001b[38;5;241m=\u001b[39m \u001b[43malign_words\u001b[49m(true[i], bad[i])\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m word_pairs:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pair[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m pair[\u001b[38;5;241m1\u001b[39m]:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'align_words' is not defined"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(true)):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        if pair[0] == pair[1]:\n",
    "            y_true.append(0)\n",
    "        else:\n",
    "            y_true.append(1)\n",
    "        \n",
    "        y_pred.append(predict_mistaken(pair[1], vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eb401b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_with_metric(text, lookup, topn=20, metric=textdistance.levenshtein):\n",
    "    similarities = Counter()\n",
    "    \n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.normalized_similarity(text, word) \n",
    "    \n",
    "    return similarities.most_common(topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd5994ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('wiki_data.txt', encoding='utf8').read()\n",
    "vocab = Counter(re.findall('\\w+', corpus.lower()))\n",
    "\n",
    "word2id = list(vocab.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "vec = CountVectorizer(analyzer='char', ngram_range=(1,1))\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b9bf8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_vec(text, X, vec, topn=20):\n",
    "    v = vec.transform([text])\n",
    "    \n",
    "    similarities = cosine_distances(v, X)[0]\n",
    "    topn = similarities.argsort()[:topn] \n",
    "    \n",
    "    return [(id2word[top], similarities[top]) for top in topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21bb72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match_ranked(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein, vocab=vocab):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn * 4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "\n",
    "    candidates_with_equal_distance = []\n",
    "\n",
    "    for n in range(1, len(closest) + 1):\n",
    "        equal_distance = len(set(dist for _, dist in closest[:n])) == 1\n",
    "        if equal_distance:\n",
    "            \n",
    "            candidates_with_equal_distance.append(closest[n - 1])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    if candidates_with_equal_distance: \n",
    "        \n",
    "        candidates_with_equal_distance = [(word, dist, P(word)) for word, dist in candidates_with_equal_distance]\n",
    "        \n",
    "        candidates_with_equal_distance.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "        remaining_candidates = closest[len(candidates_with_equal_distance):]\n",
    "\n",
    "        merged_candidates = candidates_with_equal_distance + remaining_candidates\n",
    "\n",
    "        return merged_candidates\n",
    "    else:\n",
    "        return closest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "369561c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = sum(vocab.values())\n",
    "\n",
    "def P(word, N=N):\n",
    "    return vocab[word] / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a148dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "\n",
    "    \n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05ea201c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 109 ms\n",
      "Wall time: 102 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('статике', 0.5714285714285714),\n",
       " ('кастету', 0.5714285714285714),\n",
       " ('кастет', 0.5),\n",
       " ('касте', 0.5),\n",
       " ('секстета', 0.5)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_hybrid_match('кстате', X, vec, topn=5, metric=textdistance.damerau_levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83e0dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'статике' и 'кастету' - одинаковое расстояние "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85860553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('статике', 0.5714285714285714, 1.939759225446382e-07),\n",
       " ('кастету', 0.5714285714285714, 1.939759225446382e-07),\n",
       " ('кастет', 0.5),\n",
       " ('касте', 0.5),\n",
       " ('секстета', 0.5)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match_ranked('кстате', X, vec, topn=5, metric=textdistance.damerau_levenshtein, vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62dff1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "759ebb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пояним эту мысль.\n",
      "Поясним эту мысль\n"
     ]
    }
   ],
   "source": [
    "# словарь правильных слов\n",
    "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('correct_sents.txt', encoding='utf8').read().splitlines()\n",
    "\n",
    "print(bad[2])\n",
    "print(true[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dfa35ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [token.strip(punctuation) for token in tokens_1]\n",
    "    tokens_2 = [token.strip(punctuation) for token in tokens_2]\n",
    "    \n",
    "    tokens_1 = [token for token in tokens_1 if token]\n",
    "    tokens_2 = [token for token in tokens_2 if token]\n",
    "    \n",
    "    assert len(tokens_1) == len(tokens_2)\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "258d26c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368802\n"
     ]
    }
   ],
   "source": [
    "corpus = open('wiki_data.txt', encoding='utf8').read()\n",
    "vocab = Counter(re.findall(r'\\w+', corpus.lower()))\n",
    "\n",
    "print(len(vocab)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6cc5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2872459\n"
     ]
    }
   ],
   "source": [
    "# создание словаря удалений\n",
    "def edits1(word):\n",
    "    letters = 'йцукенгшщзхъфывапролджэячсмитьбюё'\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletes = [L + R[1:] for L, R in splits if R]\n",
    "    return deletes\n",
    "\n",
    "delete_dict = {}\n",
    "for word in vocab:\n",
    "    deletions = edits1(word)\n",
    "    for deletion in deletions:\n",
    "        if deletion not in delete_dict:\n",
    "            delete_dict[deletion] = word\n",
    "\n",
    "print(len(delete_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3202ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_spelling_with_probability(word, delete_dict, vocab):\n",
    "    word_deletes = edits1(word)\n",
    "\n",
    "    possible_corrections = []\n",
    "    \n",
    "    for delete in word_deletes:\n",
    "        \n",
    "        if delete in delete_dict:\n",
    "            possible_corrections.append(delete_dict[delete])\n",
    "    \n",
    "    if possible_corrections:\n",
    "        corrected_word = max(possible_corrections, key=lambda x: P(x, N=N))\n",
    "        return corrected_word\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2df9f0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'знакома'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correct_spelling_with_probability('закомая', delete_dict, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f8c9e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'лещин'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correct_spelling_with_probability('жещин', delete_dict, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f3612b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'перспектив'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correct_spelling_with_probability('песпектива', delete_dict, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6ba52ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'низменная'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "correct_spelling_with_probability('измченная', delete_dict, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "224c182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.1-py3-none-any.whl (139 kB)\n",
      "                                              0.0/139.4 kB ? eta -:--:--\n",
      "     --                                       10.2/139.4 kB ? eta -:--:--\n",
      "     --------                              30.7/139.4 kB 330.3 kB/s eta 0:00:01\n",
      "     --------                              30.7/139.4 kB 330.3 kB/s eta 0:00:01\n",
      "     ------------------------------------ 139.4/139.4 kB 828.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\programdata\\miniconda3\\lib\\site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from ipywidgets) (8.16.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\programdata\\miniconda3\\lib\\site-packages (from ipywidgets) (5.10.1)\n",
      "Collecting widgetsnbextension~=4.0.9 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.9-py3-none-any.whl (2.3 MB)\n",
      "                                              0.0/2.3 MB ? eta -:--:--\n",
      "     -                                        0.1/2.3 MB 1.1 MB/s eta 0:00:03\n",
      "     --                                       0.1/2.3 MB 1.2 MB/s eta 0:00:02\n",
      "     ---                                      0.2/2.3 MB 1.5 MB/s eta 0:00:02\n",
      "     ----                                     0.3/2.3 MB 1.4 MB/s eta 0:00:02\n",
      "     -----                                    0.3/2.3 MB 1.5 MB/s eta 0:00:02\n",
      "     ------                                   0.4/2.3 MB 1.5 MB/s eta 0:00:02\n",
      "     --------                                 0.5/2.3 MB 1.5 MB/s eta 0:00:02\n",
      "     ---------                                0.6/2.3 MB 1.5 MB/s eta 0:00:02\n",
      "     -----------                              0.6/2.3 MB 1.6 MB/s eta 0:00:02\n",
      "     ------------                             0.7/2.3 MB 1.6 MB/s eta 0:00:01\n",
      "     --------------                           0.8/2.3 MB 1.6 MB/s eta 0:00:01\n",
      "     ---------------                          0.9/2.3 MB 1.6 MB/s eta 0:00:01\n",
      "     ----------------                         1.0/2.3 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------                       1.0/2.3 MB 1.6 MB/s eta 0:00:01\n",
      "     -------------------                      1.1/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------                    1.2/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ----------------------                   1.3/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -----------------------                  1.4/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------                1.5/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     --------------------------               1.5/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ----------------------------             1.6/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -----------------------------            1.7/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------          1.8/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------        1.9/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ----------------------------------       2.0/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------     2.1/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------    2.2/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     --------------------------------------   2.2/2.3 MB 1.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.2/2.3 MB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.3/2.3 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting jupyterlab-widgets~=3.0.9 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.9-py3-none-any.whl (214 kB)\n",
      "                                              0.0/214.9 kB ? eta -:--:--\n",
      "     -------                               41.0/214.9 kB 960.0 kB/s eta 0:00:01\n",
      "     ---------------------                  122.9/214.9 kB 1.2 MB/s eta 0:00:01\n",
      "     ----------------------------------     194.6/214.9 kB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 214.9/214.9 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: backcall in c:\\programdata\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\programdata\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\programdata\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\programdata\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in c:\\programdata\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\miniconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\programdata\\miniconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\miniconda3\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.7)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in c:\\programdata\\miniconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\miniconda3\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.1 jupyterlab-widgets-3.0.9 widgetsnbextension-4.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b6055f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592eb360388241f2a315fc99ada968db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/915 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "\n",
    "cashed = {}\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        \n",
    "        predicted = cashed.get(pair[1], correct_spelling_with_probability(pair[1], delete_dict, vocab))\n",
    "        cashed[pair[1]] = predicted\n",
    "        \n",
    "        \n",
    "        if predicted == pair[0]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1\n",
    "            if pair[0] !=  predicted:\n",
    "                correct_broken += 1\n",
    "        else:\n",
    "            total_mistaken += 1\n",
    "            if pair[0] == predicted:\n",
    "                mistaken_fixed += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
